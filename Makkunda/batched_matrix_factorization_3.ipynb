{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "from __future__ import division\n",
    "import torch\n",
    "import sys\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import os\n",
    "import copy\n",
    "from PIL import Image\n",
    "from torch import autograd\n",
    "from torch.autograd import Variable\n",
    "import scipy.misc\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision.utils import make_grid\n",
    "import pickle as pkl\n",
    "print(\"PyTorch Version: \",torch.__version__)\n",
    "print(\"Torchvision Version: \",torchvision.__version__)\n",
    "import tqdm\n",
    "from tqdm import tqdm\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_file = \"data/train_data/train_task_1_2.csv\"\n",
    "batch_size = 32\n",
    "lr = 0.0001\n",
    "num_epochs = 5\n",
    "K = 100\n",
    "total_q = 28000\n",
    "total_s = 119000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(data_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['QuestionId'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['UserId'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Question_Ans(Dataset):\n",
    "    def __init__(self, filename, mode='train'):\n",
    "        self.df = pd.read_csv(filename)\n",
    "        self.questionid = self.df['QuestionId'].values\n",
    "        self.userid = self.df['UserId'].values\n",
    "        self.ans = self.df['IsCorrect'].values\n",
    "        \n",
    "        self.ans = 2*self.ans - 1\n",
    "        \n",
    "        self.length=len(self.ans)\n",
    "        \n",
    "        \n",
    "        if(mode=='train'):\n",
    "            start=int(0*self.length)\n",
    "            end=int(0.8*self.length)\n",
    "        else:\n",
    "            start=int(0.8*self.length)\n",
    "            end=int(1*self.length)\n",
    "            \n",
    "            \n",
    "        self.questionid = self.questionid[start:end]\n",
    "        self.userid = self.userid[start:end]\n",
    "        self.ans = self.ans[start:end]\n",
    "        \n",
    "        self.length=len(self.ans)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.length\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        \n",
    "        qid = self.questionid[idx]\n",
    "        uid = self.userid[idx]\n",
    "        ans = self.ans[idx]\n",
    "        return qid,uid,ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = Question_Ans(filename=data_file,mode='train')\n",
    "val_dataset = Question_Ans(filename=data_file,mode='val')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = torch.utils.data.DataLoader(train_dataset,batch_size=batch_size, shuffle=True)\n",
    "val_dataloader = torch.utils.data.DataLoader(val_dataset,batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = {}\n",
    "dataloader['train'] = train_dataloader\n",
    "dataloader['val'] = val_dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtype=torch.FloatTensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Declare two matrices \n",
    "# Q = shape (total_q,K)\n",
    "# U = shape (total_s,K)\n",
    "Q = torch.nn.Embedding(total_q,K)\n",
    "U = torch.nn.Embedding(total_s,K)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# embedding = torch.nn.Embedding(5,8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# embedding(torch.LongTensor(np.array([3,4,3])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_qvector(questions):\n",
    "    \n",
    "#     q_list = []\n",
    "#     for i in range(questions.shape[0]):\n",
    "#         q_list.append(Q[i])\n",
    "    \n",
    "#     return torch.cat(q_list,dim=0)\n",
    "    ans = Q(torch.LongTensor(questions))\n",
    "    \n",
    "    return ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_uvector(users):\n",
    "    \n",
    "#     u_list = []\n",
    "#     for i in range(users.shape[0]):\n",
    "#         u_list.append(U[i])\n",
    "    \n",
    "#     return torch.cat(u_list,dim=0)\n",
    "#     print(users)\n",
    "    ans = U(torch.LongTensor(users))\n",
    "        \n",
    "    return ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test1 = torch.randn(32,100)\n",
    "test2 = torch.randn(32,100)\n",
    "test1 = torch.unsqueeze(test1,1)\n",
    "test2 = torch.unsqueeze(test2,2)\n",
    "print(test1.shape)\n",
    "print(test2.shape)\n",
    "res = torch.bmm(test1,test2)\n",
    "print(res.shape)\n",
    "res = torch.squeeze(res)\n",
    "print(res.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_score(qvectors,uvectors):\n",
    "    \n",
    "    q_unsq = torch.unsqueeze(qvectors, 1)\n",
    "    u_unsq = torch.unsqueeze(uvectors, 2)\n",
    "    score = torch.bmm(q_unsq,u_unsq)\n",
    "    score = torch.squeeze(score)\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_to_update = list(Q.parameters()) + list(U.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.SGD(params=params_to_update,lr=lr, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_loss = 1e9\n",
    "for epoch in range(num_epochs):\n",
    "    print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
    "    print('-' * 10)\n",
    "    # Each epoch has a training and validation phase\n",
    "    for phase in ['train', 'val']:\n",
    "        \n",
    "            \n",
    "        running_loss = 0.0\n",
    "        \n",
    "        # Iterate over data.\n",
    "        cnt = 0\n",
    "#         print(\"*********** entered \",phase,\"*********************\")\n",
    "        for questions,users,ans in tqdm(dataloader[phase]):\n",
    "            \n",
    "#             print(\"************ loaded data of one batch*******\")\n",
    "            \n",
    "            cnt = cnt + 1\n",
    "            ans = torch.tensor(ans)\n",
    "            ans = ans.type(dtype)\n",
    "            \n",
    "            qvectors = get_qvector(questions)\n",
    "            uvectors = get_uvector(users)\n",
    "            \n",
    "            \n",
    "            # zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "            # forward\n",
    "            \n",
    "            scores = get_score(qvectors,uvectors)\n",
    "            \n",
    "            loss = criterion(scores,ans)\n",
    "            \n",
    "            if phase == 'train':\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "        \n",
    "            # statistics\n",
    "            running_loss += loss.item()\n",
    "            \n",
    "            # compute correct\n",
    "            # running_corrects += torch.sum(preds == labels.data)\n",
    "            \n",
    "            if (cnt % 1000 == 0 ) :\n",
    "                print('Batch {} {} Loss: {:.4f} '.format(str(cnt),phase, running_loss/(cnt*batch_size)))\n",
    "            \n",
    "\n",
    "        epoch_loss = running_loss / len(dataloader[phase].dataset)\n",
    "\n",
    "        print(' {} Loss: {:.4f} '.format(phase, epoch_loss))\n",
    "        \n",
    "        # deep copy the model\n",
    "        if phase == 'val' and epoch_loss < best_loss:\n",
    "            best_loss = epoch_loss\n",
    "            # best_model_wts = copy.deepcopy(model.state_dict())\n",
    "            # do something about saving best matrices\n",
    "    q_file = 'models/simple_fact_q' + str(epoch+1) + '_.pkl'\n",
    "    u_file = 'models/simple_fact_u' + str(epoch+1) + '_.pkl'\n",
    "    q_f = open(q_file, 'wb')\n",
    "    u_f = open(u_file, 'wb')\n",
    "    pickle.dump(Q,q_f)\n",
    "    pickle.dump(U,u_f)\n",
    "    print()\n",
    "time_elapsed = time.time() - since\n",
    "print('Training complete in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\n",
    "print('Best val Loss: {:4f}'.format(best_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q_file = 'models/simple_fact_q.pkl'\n",
    "u_file = 'models/simple_fact_u.pkl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q_f = open(q_file, 'wb')\n",
    "u_f = open(u_file, 'wb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(Q,q_f)\n",
    "pickle.dump(U,u_f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
