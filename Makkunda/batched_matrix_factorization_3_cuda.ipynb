{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Automatic pdb calling has been turned ON\n"
     ]
    }
   ],
   "source": [
    "%pdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch Version:  1.5.1\n",
      "Torchvision Version:  0.6.0a0+35d732a\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "from __future__ import division\n",
    "import torch\n",
    "import sys\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import os\n",
    "import copy\n",
    "from PIL import Image\n",
    "from torch import autograd\n",
    "from torch.autograd import Variable\n",
    "import scipy.misc\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision.utils import make_grid\n",
    "import pickle as pkl\n",
    "print(\"PyTorch Version: \",torch.__version__)\n",
    "print(\"Torchvision Version: \",torchvision.__version__)\n",
    "import tqdm\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_file = \"../Data/data/train_data/train_task_1_2_sample.csv\"\n",
    "log_file = \"../logs/task_1_log.txt\"\n",
    "batch_size = 32\n",
    "lr = 0.0001\n",
    "num_epochs = 100\n",
    "K = 100\n",
    "total_q = 28000\n",
    "total_s = 119000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open(log_file,'a')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.read_csv(data_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df['QuestionId'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df['UserId'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Question_Ans(Dataset):\n",
    "    def __init__(self, filename, mode='train'):\n",
    "        self.df = pd.read_csv(filename)\n",
    "        self.questionid = self.df['QuestionId'].values\n",
    "        self.userid = self.df['UserId'].values\n",
    "        self.ans = self.df['IsCorrect'].values\n",
    "        \n",
    "        self.ans = 2*self.ans - 1\n",
    "        \n",
    "        self.length=len(self.ans)\n",
    "        \n",
    "        \n",
    "        if(mode=='train'):\n",
    "            start=int(0*self.length)\n",
    "            end=int(0.8*self.length)\n",
    "        elif(mode=='val'):\n",
    "            start=int(0.8*self.length)\n",
    "            end=int(1*self.length)\n",
    "        else:\n",
    "            start = 0\n",
    "            end = int(self.length)\n",
    "            \n",
    "            \n",
    "        self.questionid = self.questionid[start:end]\n",
    "        self.userid = self.userid[start:end]\n",
    "        self.ans = self.ans[start:end]\n",
    "        \n",
    "        self.length=len(self.ans)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.length\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        \n",
    "        qid = self.questionid[idx]\n",
    "        uid = self.userid[idx]\n",
    "        ans = self.ans[idx]\n",
    "        return qid,uid,ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = Question_Ans(filename=data_file,mode='train')\n",
    "val_dataset = Question_Ans(filename=data_file,mode='val')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = torch.utils.data.DataLoader(train_dataset,batch_size=batch_size, shuffle=True)\n",
    "val_dataloader = torch.utils.data.DataLoader(val_dataset,batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = {}\n",
    "dataloader['train'] = train_dataloader\n",
    "dataloader['val'] = val_dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtype=torch.FloatTensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Declare two matrices \n",
    "# Q = shape (total_q,K)\n",
    "# U = shape (total_s,K)\n",
    "Q = torch.nn.Embedding(total_q,K)\n",
    "U = torch.nn.Embedding(total_s,K)\n",
    "\n",
    "Q = Q.to(device)\n",
    "U = U.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# embedding = torch.nn.Embedding(5,8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# embedding(torch.LongTensor(np.array([3,4,3])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_qvector(questions):\n",
    "    ans = Q(torch.LongTensor(questions).to(device))\n",
    "    \n",
    "    ans = ans.to(device)\n",
    "    return ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_uvector(users):\n",
    "    ans = U(torch.LongTensor(users).to(device))\n",
    "    ans = ans.to(device)\n",
    "    return ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 1, 100])\n",
      "torch.Size([32, 100, 1])\n",
      "torch.Size([32, 1, 1])\n",
      "torch.Size([32])\n"
     ]
    }
   ],
   "source": [
    "test1 = torch.randn(32,100)\n",
    "test2 = torch.randn(32,100)\n",
    "test1 = torch.unsqueeze(test1,1)\n",
    "test2 = torch.unsqueeze(test2,2)\n",
    "print(test1.shape)\n",
    "print(test2.shape)\n",
    "res = torch.bmm(test1,test2)\n",
    "print(res.shape)\n",
    "res = torch.squeeze(res)\n",
    "print(res.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_score(qvectors,uvectors):\n",
    "    q_unsq = torch.unsqueeze(qvectors, 1)\n",
    "    u_unsq = torch.unsqueeze(uvectors, 2)\n",
    "    score = torch.bmm(q_unsq,u_unsq)\n",
    "    score = torch.squeeze(score)\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_to_update = list(Q.parameters()) + list(U.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.SGD(params=params_to_update,lr=lr, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/36531 [00:00<?, ?it/s]/Users/ayushd/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:19: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  0%|          | 1/36531 [00:00<1:41:52,  5.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/99\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 1002/36531 [00:50<28:58, 20.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 1000 train Loss: 3.1478 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 2002/36531 [01:37<34:41, 16.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 2000 train Loss: 3.1680 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 3004/36531 [02:28<27:35, 20.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 3000 train Loss: 3.1754 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|█         | 4003/36531 [03:20<26:41, 20.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 4000 train Loss: 3.1595 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 4303/36531 [03:35<29:04, 18.48it/s]"
     ]
    }
   ],
   "source": [
    "best_loss = 1e9\n",
    "for epoch in range(num_epochs):\n",
    "    print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
    "    print('-' * 10)\n",
    "    # Each epoch has a training and validation phase\n",
    "    for phase in ['train', 'val']:\n",
    "        \n",
    "            \n",
    "        running_loss = 0.0\n",
    "        \n",
    "        # Iterate over data.\n",
    "        cnt = 0\n",
    "#         print(\"*********** entered \",phase,\"*********************\")\n",
    "        for questions,users,ans in tqdm(dataloader[phase]):\n",
    "            \n",
    "#             print(\"************ loaded data of one batch*******\")\n",
    "            \n",
    "            cnt = cnt + 1\n",
    "            ans = torch.tensor(ans)\n",
    "            ans = ans.type(dtype)\n",
    "            ans = ans.to(device)\n",
    "            \n",
    "            qvectors = get_qvector(questions)\n",
    "            uvectors = get_uvector(users)\n",
    "            \n",
    "            \n",
    "            # zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "            # forward\n",
    "            \n",
    "            scores = get_score(qvectors,uvectors)\n",
    "            \n",
    "            loss = criterion(scores,ans)\n",
    "            \n",
    "            if phase == 'train':\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "        \n",
    "            # statistics\n",
    "            running_loss += loss.item()\n",
    "            \n",
    "            # compute correct\n",
    "            # running_corrects += torch.sum(preds == labels.data)\n",
    "            \n",
    "            if (cnt % 1000 == 0 ) :\n",
    "                print('Batch {} {} Loss: {:.4f} '.format(str(cnt),phase, running_loss/(cnt*batch_size)))\n",
    "                print('Batch {} {} Loss: {:.4f} '.format(str(cnt),phase, running_loss/(cnt*batch_size)),file=f)\n",
    "            \n",
    "\n",
    "        epoch_loss = running_loss / len(dataloader[phase].dataset)\n",
    "\n",
    "        print(' {} Loss: {:.4f} '.format(phase, epoch_loss))\n",
    "        print(' {} Loss: {:.4f} '.format(phase, epoch_loss),file=f)\n",
    "        \n",
    "        # deep copy the model\n",
    "        if phase == 'val' and epoch_loss < best_loss:\n",
    "            best_loss = epoch_loss\n",
    "            \n",
    "            q_file = '../Weights/simple_fact_q' + '_best' + '.pkl'\n",
    "            u_file = '../Weights/simple_fact_u' + '_best' + '.pkl'\n",
    "            q_f = open(q_file, 'wb')\n",
    "            u_f = open(u_file, 'wb')\n",
    "            pickle.dump(Q,q_f)\n",
    "            pickle.dump(U,u_f)\n",
    "        \n",
    "        q_file = '../Weights/simple_fact_q_' + str(epoch+1) + '.pkl'\n",
    "        u_file = '../Weights/simple_fact_u_' + str(epoch+1) + '.pkl'\n",
    "        q_f = open(q_file, 'wb')\n",
    "        u_f = open(u_file, 'wb')\n",
    "        pickle.dump(Q,q_f)\n",
    "        pickle.dump(U,u_f)\n",
    "    print()\n",
    "time_elapsed = time.time() - since\n",
    "print('Training complete in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\n",
    "print('Best val Loss: {:4f}'.format(best_loss))\n",
    "\n",
    "print('Training complete in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60),file=f)\n",
    "print('Best val Loss: {:4f}'.format(best_loss),file=f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
